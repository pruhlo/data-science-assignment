{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b5d3e30",
   "metadata": {},
   "source": [
    "<img src='https://github.com/pruhlo/data-science-assignment/blob/master/assets/Quick%20task2-1.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc543e0",
   "metadata": {},
   "source": [
    "* Завантажити файл: [covid_19_data.csv](https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset)\n",
    "* Вивести перелік країн та кількість людей, у яких виявлений вірус (викорисатити для цієї задачі dict)\n",
    "* Dict з агрегованими даними запакувати за допомогою модуля [pickle][link] та відправити іншому студенту курсу.\n",
    "* Отримати файл [pickle][link] від свого колеги, розпакувати його; порівняти свій результат із результатом колеги.\n",
    "\n",
    "<a href='https://github.com/pruhlo/data-science-assignment/blob/master/assets/Quick%20task2-1.png?raw=true'>Origin Quick task2-1</a>\n",
    "\n",
    "[link]: http://nbviewer.org/github/pruhlo/NB/blob/master/pickle%20module.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba01b5",
   "metadata": {},
   "source": [
    "### Column Description\n",
    "Main file in this dataset is covid_19_data.csv and the detailed descriptions are below.\n",
    "\n",
    "covid_19_data.csv\n",
    "\n",
    "* Sno - Serial number\n",
    "* ObservationDate - Date of the observation in MM/DD/YYYY\n",
    "* Province/State - Province or state of the observation (Could be empty when missing)\n",
    "* Country/Region - Country of observation\n",
    "* Last Update - Time in UTC at which the row is updated for the given province or country. (Not standardised and so please clean before using it)\n",
    "* Confirmed - Cumulative number of confirmed cases till that date\n",
    "* Deaths - Cumulative number of of deaths till that date\n",
    "* Recovered - Cumulative number of recovered cases till that date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67245ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNo</th>\n",
       "      <th>ObservationDate</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SNo ObservationDate Province/State  Country/Region      Last Update  \\\n",
       "0    1      01/22/2020          Anhui  Mainland China  1/22/2020 17:00   \n",
       "1    2      01/22/2020        Beijing  Mainland China  1/22/2020 17:00   \n",
       "2    3      01/22/2020      Chongqing  Mainland China  1/22/2020 17:00   \n",
       "3    4      01/22/2020         Fujian  Mainland China  1/22/2020 17:00   \n",
       "4    5      01/22/2020          Gansu  Mainland China  1/22/2020 17:00   \n",
       "\n",
       "   Confirmed  Deaths  Recovered  \n",
       "0        1.0     0.0        0.0  \n",
       "1       14.0     0.0        0.0  \n",
       "2        6.0     0.0        0.0  \n",
       "3        1.0     0.0        0.0  \n",
       "4        0.0     0.0        0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('assets/covid_19_data.csv')\n",
    "#https://raw.githubusercontent.com/pruhlo/data-science-assignment/master/assets/covid_19_data.csv\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e33758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вивести перелік країн та кількість людей, у яких виявлений вірус \n",
    "Dict = df.groupby('Country/Region').sum()['Confirmed'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d477659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Відкрити файл для запису\n",
    "f = open('myfile.bin', 'wb')\n",
    "\n",
    "# Зберегти словник Dict у файлі f\n",
    "pickle.dump(Dict, f)\n",
    "\n",
    "# Закрити файл\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0db2252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict =  {' Azerbaijan': 1.0, \"('St. Martin',)\": 2.0, 'Afghanistan': 17026442.0, 'Albania': 19768869.0, 'Algeria': 27684358.0, 'Andorra': 2379802.0, 'Angola': 4764863.0, 'Antigua and Barbuda': 143868.0, 'Argentina': 504802880.0, 'Armenia': 42536277.0, 'Aruba': 19.0, 'Australia': 9447438.0, 'Austria': 97965875.0, 'Azerbaijan': 52366764.0, 'Bahamas': 2139331.0, 'Bahamas, The': 10.0, 'Bahrain': 33934748.0, 'Bangladesh': 161494811.0, 'Barbados': 474762.0, 'Belarus': 65435028.0, 'Belgium': 179009886.0, 'Belize': 2399352.0, 'Benin': 1365462.0, 'Bhutan': 196080.0, 'Bolivia': 61346449.0, 'Bosnia and Herzegovina': 31257028.0, 'Botswana': 6063426.0, 'Brazil': 2653587540.0, 'Brunei': 71229.0, 'Bulgaria': 56530042.0, 'Burkina Faso': 2249316.0, 'Burma': 27717649.0, 'Burundi': 492722.0, 'Cabo Verde': 3941085.0, 'Cambodia': 955901.0, 'Cameroon': 11346589.0, 'Canada': 193497537.0, 'Cape Verde': 1.0, 'Cayman Islands': 3.0, 'Central African Republic': 1776825.0, 'Chad': 883727.0, 'Channel Islands': 1.0, 'Chile': 232444395.0, 'China': 0.0, 'Colombia': 515307146.0, 'Comoros': 579705.0, 'Congo (Brazzaville)': 2286750.0, 'Congo (Kinshasa)': 6148539.0, 'Costa Rica': 47395838.0, 'Croatia': 50531146.0, 'Cuba': 11110101.0, 'Curacao': 2.0, 'Cyprus': 7736086.0, 'Czech Republic': 237860726.0, 'Denmark': 42700338.0, 'Diamond Princess': 306872.0, 'Djibouti': 2387030.0, 'Dominica': 31141.0, 'Dominican Republic': 57000335.0, 'East Timor': 1.0, 'Ecuador': 74790536.0, 'Egypt': 50168167.0, 'El Salvador': 14619435.0, 'Equatorial Guinea': 1919781.0, 'Eritrea': 522945.0, 'Estonia': 13834670.0, 'Eswatini': 3401276.0, 'Ethiopia': 41388062.0, 'Faroe Islands': 10.0, 'Fiji': 20720.0, 'Finland': 13103437.0, 'France': 855188962.0, 'French Guiana': 117.0, 'Gabon': 4237601.0, 'Gambia': 1250677.0, 'Gambia, The': 4.0, 'Georgia': 51183744.0, 'Germany': 524166833.0, 'Ghana': 20784664.0, 'Gibraltar': 7.0, 'Greece': 44502618.0, 'Greenland': 3.0, 'Grenada': 30738.0, 'Guadeloupe': 187.0, 'Guam': 6.0, 'Guatemala': 44774712.0, 'Guernsey': 3.0, 'Guinea': 4860849.0, 'Guinea-Bissau': 973695.0, 'Guyana': 2068280.0, 'Haiti': 3532804.0, 'Holy See': 8448.0, 'Honduras': 41138599.0, 'Hong Kong': 2655935.0, 'Hungary': 98903229.0, 'Iceland': 1729527.0, 'India': 3226768088.0, 'Indonesia': 265186050.0, 'Iran': 400909778.0, 'Iraq': 187310643.0, 'Ireland': 42974124.0, 'Israel': 153263218.0, 'Italy': 636694305.0, 'Ivory Coast': 9253034.0, 'Jamaica': 5774810.0, 'Japan': 89378076.0, 'Jersey': 6.0, 'Jordan': 90344299.0, 'Kazakhstan': 70060029.0, 'Kenya': 27728648.0, 'Kiribati': 21.0, 'Kosovo': 15865976.0, 'Kuwait': 53341259.0, 'Kyrgyzstan': 22692500.0, 'Laos': 58871.0, 'Latvia': 15266130.0, 'Lebanon': 71885997.0, 'Lesotho': 1705201.0, 'Liberia': 576370.0, 'Libya': 29458062.0, 'Liechtenstein': 500670.0, 'Lithuania': 36339959.0, 'Luxembourg': 12154223.0, 'MS Zaandam': 3824.0, 'Macau': 20605.0, 'Madagascar': 6579780.0, 'Mainland China': 40822596.0, 'Malawi': 5235180.0, 'Malaysia': 53546912.0, 'Maldives': 5502303.0, 'Mali': 2273550.0, 'Malta': 4556210.0, 'Marshall Islands': 804.0, 'Martinique': 172.0, 'Mauritania': 4104867.0, 'Mauritius': 235313.0, 'Mayotte': 21.0, 'Mexico': 460463678.0, 'Micronesia': 129.0, 'Moldova': 42907803.0, 'Monaco': 364464.0, 'Mongolia': 2388966.0, 'Montenegro': 14990089.0, 'Morocco': 104557135.0, 'Mozambique': 9979000.0, 'Namibia': 7912632.0, 'Nepal': 67252242.0, 'Netherlands': 234955991.0, 'New Zealand': 836280.0, 'Nicaragua': 1929682.0, 'Niger': 1047041.0, 'Nigeria': 33407947.0, 'North Ireland': 1.0, 'North Macedonia': 23650041.0, 'Norway': 17283377.0, 'Oman': 42831069.0, 'Others': 26228.0, 'Pakistan': 165572396.0, 'Palestine': 86.0, 'Panama': 73445278.0, 'Papua New Guinea': 886555.0, 'Paraguay': 38225829.0, 'Peru': 361150607.0, 'Philippines': 164420468.0, 'Poland': 380680836.0, 'Portugal': 141962632.0, 'Puerto Rico': 3.0, 'Qatar': 52791589.0, 'Republic of Ireland': 21.0, 'Republic of the Congo': 1.0, 'Reunion': 137.0, 'Romania': 173082798.0, 'Russia': 930548849.0, 'Rwanda': 3770080.0, 'Saint Barthelemy': 17.0, 'Saint Kitts and Nevis': 11211.0, 'Saint Lucia': 502993.0, 'Saint Vincent and the Grenadines': 229517.0, 'Samoa': 481.0, 'San Marino': 851906.0, 'Sao Tome and Principe': 470914.0, 'Saudi Arabia': 123111168.0, 'Senegal': 7893507.0, 'Serbia': 95624419.0, 'Seychelles': 608196.0, 'Sierra Leone': 1008350.0, 'Singapore': 21476559.0, 'Slovakia': 55789871.0, 'Slovenia': 35538663.0, 'Solomon Islands': 3818.0, 'Somalia': 2211790.0, 'South Africa': 345940039.0, 'South Korea': 20814483.0, 'South Sudan': 1748600.0, 'Spain': 649111763.0, 'Sri Lanka': 15676007.0, 'St. Martin': 2.0, 'Sudan': 7632455.0, 'Suriname': 2148896.0, 'Sweden': 142264880.0, 'Switzerland': 115902800.0, 'Syria': 3494790.0, 'Taiwan': 339919.0, 'Tajikistan': 3988242.0, 'Tanzania': 205081.0, 'Thailand': 7139288.0, 'The Bahamas': 3.0, 'The Gambia': 1.0, 'Timor-Leste': 183796.0, 'Togo': 1691382.0, 'Trinidad and Tobago': 2119871.0, 'Tunisia': 44779270.0, 'Turkey': 618940956.0, 'UK': 783794384.0, 'US': 6049145667.0, 'Uganda': 8016407.0, 'Ukraine': 310910152.0, 'United Arab Emirates': 83739255.0, 'Uruguay': 17112011.0, 'Uzbekistan': 22207571.0, 'Vanuatu': 406.0, 'Vatican City': 4.0, 'Venezuela': 35958070.0, 'Vietnam': 615984.0, 'West Bank and Gaza': 41819444.0, 'Yemen': 962066.0, 'Zambia': 13493953.0, 'Zimbabwe': 6484581.0, 'occupied Palestinian territory': 25.0}\n"
     ]
    }
   ],
   "source": [
    "# Відкрити файл для читання\n",
    "f = open('myfile.bin', 'rb')\n",
    "\n",
    "# Прочитати словник із файлу\n",
    "D = pickle.load(f)\n",
    "\n",
    "# Закрити файл\n",
    "f.close()\n",
    "\n",
    "# 5. Вивести словник\n",
    "print('Dict = ', D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5beb1",
   "metadata": {},
   "source": [
    "<img src='https://github.com/pruhlo/data-science-assignment/blob/master/assets/Quick%20task2-2.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74896d",
   "metadata": {},
   "source": [
    "<a href='https://github.com/pruhlo/data-science-assignment/blob/master/assets/Quick%20task2-2.png?raw=true'>Origin Quick task2-2</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea368369",
   "metadata": {},
   "source": [
    "* Ознайомитися із структурою сайту https://www.ukr.net/ua/\n",
    "* За допомогою бібліотеки bs4 «розпарсити» сайт, зберегти всі новини. Створити структуру JSON форматі із полями: категорія новини, дата новини, текст новини.\n",
    "* Відправити JSON куратору курсу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0897a887",
   "metadata": {},
   "source": [
    "[link stackoverflow](https://stackoverflow.com/questions/70369790/python-requests-response-403-forbidden)\n",
    "Веб-сайт захищено CloudFlare. За допомогою стандартних засобів є мінімальний шанс отримати доступ до веб-сайту через автоматизацію, таку як `request` або `selenium`. Ви бачите 403, оскільки ваш клієнт визначено як робот. Можуть бути деякі довільні методи обходу CloudFlare, які можна знайти в інших місцях, але веб-сайт працює належним чином. Має бути маса даних, надісланих через заголовки та файли cookie, які показують, що ваш запит дійсний, і оскільки ви просто надсилаєте лише агент користувача, запускається CloudFlare. Простого спуфінгу іншого агента користувача недостатньо, щоб не запустити капчу, CloudFlare перевіряє БАГАТО речей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16e8ee",
   "metadata": {},
   "source": [
    "### Інше завдання\n",
    "\n",
    "Зберіть новини за найбільш популярними темами на сайті https://www.pravda.com.ua\n",
    "\n",
    "- розпарсіть сторінку з темами: https://www.pravda.com.ua/tags/\n",
    "- виберіть лише найбільш популярні теми (такі як \"Верховна Рада\")\n",
    "- зберіть новини по усіх вибраних темах (розпарсити відповідні сторінки, такі як https://www.pravda.com.ua/tags/verkhovna-rada/)\n",
    "- збережіть новини у форматі JSON\n",
    "\n",
    "По кожній новині мають бути записані такі поля\n",
    "\n",
    "- назва теми\n",
    "- лінк теми (посилання, адреса)\n",
    "- назва новини\n",
    "- лінк новини (посилання, адреса)\n",
    "- дата\n",
    "- час\n",
    "- джерело, розділ (такі як \"Новини\", \"Публікації\")\n",
    "- короткий опис новини (якщо є)\n",
    "- автор статті (якщо є, наприклад у розділі \"Публікації\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0247c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def make_req(url, timeout=100):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",}\n",
    "    resp = __import__('requests').get(url, headers=headers, timeout=timeout)\n",
    "    return resp\n",
    "\n",
    "def get_date_time_source_author(string):\n",
    "    try:\n",
    "        date = string.split('—')[0].split(',')[0]\n",
    "        time = string.split('—')[0].split(',')[1]\n",
    "        source = string.split('—')[1]\n",
    "        author_s = string.split('—')[2]\n",
    "    except IndexError:\n",
    "        try:\n",
    "            author_s = None\n",
    "            source = string.split('—')[1]\n",
    "        except IndexError:\n",
    "            author_s = None\n",
    "            source = None\n",
    "    return date, time, source, author_s\n",
    "\n",
    "def get_link(link_str):\n",
    "    if link_str.split('/')[0] == 'https:':\n",
    "        return link_str\n",
    "    else:\n",
    "        return 'https://www.pravda.com.ua' + link_str # 'https://www.pravda.com.ua' + \n",
    "\n",
    "url = f'https://www.pravda.com.ua/tags/'\n",
    "resp = make_req(url)\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "base_select_tags = 'a.tag1'\n",
    "list_tags = [i.get('href') for i in soup.select(f'{base_select_tags}')]\n",
    "name_topics = [i.text for i in soup.select(f'{base_select_tags}')]\n",
    "d_link = dict(zip(list_tags, name_topics))\n",
    "\n",
    "link_list_tags = map(lambda string: f'https://www.pravda.com.ua' + string, list_tags)\n",
    "\n",
    "df = pd.DataFrame(columns=['name_topic', 'topic_link', 'call_news', 'link', 'date', 'time', 'source',\n",
    "                           'description_news', 'author_s', ])\n",
    "\n",
    "for url in link_list_tags:\n",
    "    response = make_req(url)\n",
    "    soup_ = BeautifulSoup(response.text, 'html.parser')\n",
    "    topic_link = url\n",
    "    name_topic = d_link[url.replace('https://www.pravda.com.ua', '')]\n",
    "    base_select_news_tags = 'div.article_list'\n",
    "    for i in soup_.select('div.article_list'):\n",
    "        link = get_link(i.a['href']) # лінк новини (посилання, адреса)\n",
    "        date, time, source, author_s = get_date_time_source_author(i.div(class_= 'article_author')[0].text) # дата - час - джерело, розділ автор статті\n",
    "        call_news = i.a.text.strip() # назва новини\n",
    "        description_news = i.div(class_='article_subheader')[0].text # короткий опис новини\n",
    "        new_row = {'name_topic':name_topic, 'topic_link':topic_link, 'call_news':call_news,\n",
    "                   'link':link, 'date':date, 'time':time, 'source':source,\n",
    "                   'description_news':description_news, 'author_s':author_s,}\n",
    "        df = df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72b73acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "json = df.to_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
