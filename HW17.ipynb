{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198d834b-c2c0-4d37-bba8-a676b9b29f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_imdb_dataframe():\n",
    "    \"\"\"\n",
    "    Downloads and extracts the IMDB dataset from a given URL and returns it as a pandas DataFrame.\n",
    "\n",
    "    The IMDB dataset contains 50,000 movie reviews for natural language processing or text analytics. \n",
    "    This dataset is used for binary sentiment classification and includes 25,000 highly polar movie reviews \n",
    "    for training and 25,000 for testing. The goal is to predict the number of positive and negative reviews \n",
    "    using classification or deep learning algorithms.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the IMDB dataset.\n",
    "    \"\"\"\n",
    "    # URL of the dataset\n",
    "    url = 'https://github.com/pruhlo/data_ML/raw/master/IMDB_Dataset.tar.xz'\n",
    "    \n",
    "    # Download the tar.xz file\n",
    "    response = requests.get(url, stream=True)\n",
    "    tar_xz_path = 'IMDB_Dataset.tar.xz'\n",
    "    \n",
    "    with open(tar_xz_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    \n",
    "    # Extract the tar.xz file\n",
    "    with tarfile.open(tar_xz_path, 'r:xz') as tar:\n",
    "        tar.extractall()\n",
    "\n",
    "    # Assuming the CSV file is named 'IMDB Dataset.csv' inside the tar.xz archive\n",
    "    csv_file_path = 'IMDB Dataset.csv'\n",
    "    \n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Clean up the downloaded and extracted files\n",
    "    os.remove(tar_xz_path)\n",
    "    os.remove(csv_file_path)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d997fec2-5112-428b-a7ec-3c591b2d9d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d313a85-5eef-464b-b379-666fc1799831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e9b369b-c527-4c80-b9bf-964dd0bcd2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40000/40000 [03:44<00:00, 178.47 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:56<00:00, 177.34 examples/s]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\users\\admin\\downloads\\ml\\18. transformers\\–¥–∑ 17. —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∏\\myenv\\lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 9:56:33, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.298600</td>\n",
       "      <td>0.278416</td>\n",
       "      <td>0.883500</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.896200</td>\n",
       "      <td>0.884961</td>\n",
       "      <td>0.955270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.204100</td>\n",
       "      <td>0.303191</td>\n",
       "      <td>0.886800</td>\n",
       "      <td>0.879364</td>\n",
       "      <td>0.896600</td>\n",
       "      <td>0.887899</td>\n",
       "      <td>0.958403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 20:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.3032\n",
      "eval_accuracy: 0.8868\n",
      "eval_precision: 0.8794\n",
      "eval_recall: 0.8966\n",
      "eval_f1: 0.8879\n",
      "eval_roc_auc: 0.9584\n",
      "eval_runtime: 1243.2427\n",
      "eval_samples_per_second: 8.0430\n",
      "eval_steps_per_second: 0.5030\n",
      "epoch: 2.0000\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch\n",
    "\n",
    "# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è IMDB –¥–∞—Ç–∞—Å–µ—Ç—É\n",
    "df = get_imdb_dataframe()\n",
    "\n",
    "# –ü–µ—Ä–µ–π–º–µ–Ω—É–≤–∞–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —è—Å–Ω–æ—Å—Ç—ñ\n",
    "df.columns = ['review', 'sentiment']\n",
    "\n",
    "# –ú–∞–ø—ñ–Ω–≥ sentiment –Ω–∞ –±—ñ–Ω–∞—Ä–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è (positive: 1, negative: 0)\n",
    "df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# –ü–æ–¥—ñ–ª –¥–∞—Ç–∞—Å–µ—Ç—É –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—É —ñ —Ç–µ—Å—Ç–æ–≤—É –≤–∏–±—ñ—Ä–∫–∏\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "\n",
    "# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –¥–æ —Ñ–æ—Ä–º–∞—Ç—É Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df[['review', 'label']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['review', 'label']])\n",
    "\n",
    "# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ç–æ—Ä–∞ DistilBERT\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# –¢–æ–∫–µ–Ω—ñ–∑–∞—Ü—ñ—è –¥–∞—Ç–∞—Å–µ—Ç—É –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –æ–±–º–µ–∂–µ–Ω–Ω—è max_length –¥–æ 128 —Å–∏–º–≤–æ–ª—ñ–≤\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['review'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ DistilBERT –¥–ª—è –±—ñ–Ω–∞—Ä–Ω–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∑ –≤–∫–ª—é—á–µ–Ω–Ω—è–º –∑–º—ñ—à–∞–Ω–æ—ó —Ç–æ—á–Ω–æ—Å—Ç—ñ (fp16)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,  # –ó–º–µ–Ω—à–µ–Ω–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –µ–ø–æ—Ö\n",
    "    weight_decay=0.01,\n",
    "    fp16=True  # –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –∑–º—ñ—à–∞–Ω–æ—ó —Ç–æ—á–Ω–æ—Å—Ç—ñ –¥–ª—è –ø—Ä–∏—à–≤–∏–¥—à–µ–Ω–Ω—è\n",
    ")\n",
    "\n",
    "# –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    precision = precision_score(p.label_ids, preds)\n",
    "    recall = recall_score(p.label_ids, preds)\n",
    "    f1 = f1_score(p.label_ids, preds)\n",
    "\n",
    "    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è ROC AUC\n",
    "    roc_auc = roc_auc_score(p.label_ids, torch.nn.functional.softmax(torch.tensor(p.predictions), dim=1)[:, 1].numpy())\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "\n",
    "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –µ–∫–∑–µ–º–ø–ª—è—Ä—É Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ\n",
    "trainer.train()\n",
    "\n",
    "# –û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª—ñ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ñ–π –≤–∏–±—ñ—Ä—Ü—ñ\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# –í–∏–≤–µ–¥–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –æ—Ü—ñ–Ω–∫–∏\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6633c7-e7ad-4bc3-af35-e1a6c81f5ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
